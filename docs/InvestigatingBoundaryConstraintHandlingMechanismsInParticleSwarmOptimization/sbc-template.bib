% Encoding: UTF-8

@misc{uci:mlr,
  author    = {M. Lichman},
  year      = {2013},
  title     = {{UCI} Machine Learning Repository},
  url       = {http://archive.ics.uci.edu/ml},
  institution = {University of California, Irvine, School of Information and Computer Sciences},
}

@Article{kennedy:pso,
  author    = {J Kennedy and R C Eberhart},
  title     = {Particle swarm optimization},
  journal   = {Micro Machine and Human Science},
  year      = {1995},
  volume    = {5},
  number    = {500},
  pages     = {39â€“43},
  abstract  = {In this paper, the utilization of different chaotic systems as pseudo-random number generators (PRNGs) for velocity calculation in the PSO algorithm are proposed. Two chaos-based PRNGs are used alternately within one run of the PSO algorithm and dynamically switched over when a certain criterion is met. By using this unique technique, it is possible to improve the performance of PSO algorithm as it is demonstrated on different benchmark functions.},
  publisher = {Proceedings of the Sixth International Symposium},
  url       = {https://link.springer.com/article/10.1007/s00500-014-1222-z},
}

@Conference{vanwyk:overfitting-psoffnn,
  author       = {Andrich Bosof van Wyk and Andries Petrus Engelbrecht},
  title        = {Overfitting by PSO trained feedforward neural networks},
  booktitle    = {IEEE Congress on Evolutionary Computation},
  year         = {2010},
  month        = jul,
  organization = {IEEE},
  publisher    = {IEEE},
  abstract     = {The purpose of this paper is to investigate the overfitting behavior of particle swarm optimization (PSO) trained neural networks. Neural networks trained with PSOs using the global best, local best and Von Neumann information sharing topologies are investigated. Experiments are conducted on five classification and five time series regression problems. It is shown that differences exist in the degree of overfitting between the different topologies. Additionally, non-convergence of the swarms is witnessed, which is hypothetically attributed to the use of a bounded activation function in the neural networks. The hypothesis is supported by experiments conducted using an unbounded activation function in the neural network hidden layer, which lead to convergent swarms. Additionally this also lead to drastically reduced overfitting by the neural networks.},
  file         = {Overfitting by PSO trained feedforward neural networks:/home/qweenink/Dropbox/uni/cos700/Research/PapersToRead/p2/06.overfitting_andrich_OverfittingBehaviourPSOonNNtraining.pdf:PDF},
  keywords     = {anna, PSO trained FFNN, PSO, NN, rank4},
  review       = {Measuring overfitting in PSO trained FFNN},
  timestamp    = {2017-03-21},
  url          = {http://ieeexplore.ieee.org/abstract/document/5586333/?section=abstract},
}

@Conference{anna:meas-sat-nn,
  author       = {Anna Rakitianskaia and Andries Engelbrecht},
  title        = {Measuring Saturation in Neural Networks},
  booktitle    = {Symposium Series on Computational Intelligence},
  year         = {2015},
  month        = dec,
  organization = {IEEE},
  publisher    = {IEEE},
  file         = {Measuring Saturation in Neural Networks:/home/qweenink/Dropbox/uni/cos700/Research/PapersToRead/p2/09.Anna_HowToMeasureSaturationInNN.pdf:PDF},
  keywords     = {anna, Artificial neural networks, Training, Optimization, Biological neural networks, Benchmark testing, Histograms, Computer science, rank4},
  timestamp    = {2017-03-21},
  url          = {http://ieeexplore.ieee.org/abstract/document/7376778/},
}

@Comment{jabref-meta: databaseType:bibtex;}
